{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3acb49",
   "metadata": {
    "papermill": {
     "duration": 0.00762,
     "end_time": "2025-04-13T19:09:44.928597",
     "exception": false,
     "start_time": "2025-04-13T19:09:44.920977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ScholarAI: An Intelligent AI Agent for Personalized Learning\n",
    "\n",
    "ScholarAI is a generative AI-powered learning assistant designed to help students study more effectively using their own materials. Built using LangChain v0.1+, Gemini, and modern GenAI capabilities, ScholarAI enables personalized, grounded, and interactive academic support.\n",
    "\n",
    "In this notebook, I demonstrate how ScholarAI can:\n",
    "\n",
    "‚úÖ Summarize research papers into concise study notes\n",
    "\n",
    "‚úÖ Answer personalized questions based on user-uploaded content using RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "This capstone project was developed as part of the 5-Day GenAI Intensive Course by Google and Kaggle, and highlights practical use of few-shot prompting, retrieval-based Q&A, and function calling in a real-world educational scenario.\n",
    "\n",
    "**Presentation of the Project:** https://gamma.app/docs/ScholarAI-Academic-Assistant-with-Summarization-and-RAG-QA-bgbgzr35625kdy0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd0d0f",
   "metadata": {
    "papermill": {
     "duration": 0.006657,
     "end_time": "2025-04-13T19:09:44.942467",
     "exception": false,
     "start_time": "2025-04-13T19:09:44.935810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Features Used in ScholarAI Project\n",
    "The following GenAI features from the list were successfully implemented:\n",
    "\n",
    "* **Few-shot prompting** ‚Äì Custom prompt templates were used to guide the summarization and Q&A responses.\n",
    "* **Document understanding** ‚Äì Academic texts were split, embedded, and processed using LangChain's document tools.\n",
    "* **Embeddings** ‚Äì Text chunks were converted into embeddings using `GoogleGenerativeAIEmbeddings`.\n",
    "* **Retrieval-Augmented Generation (RAG)** ‚Äì The core system retrieves relevant documents before generating answers.\n",
    "* **Vector search/vector store/vector database** ‚Äì Used `InMemoryVectorStore` for similarity-based retrieval of academic content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d768374",
   "metadata": {
    "papermill": {
     "duration": 0.006591,
     "end_time": "2025-04-13T19:09:44.956057",
     "exception": false,
     "start_time": "2025-04-13T19:09:44.949466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Diagram for ScholarAI\n",
    "\n",
    "![ScholarAI Diagram](https://i.postimg.cc/KcMBr9Qv/Diagram-for-Scholar-AI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba5f4d",
   "metadata": {
    "papermill": {
     "duration": 0.006515,
     "end_time": "2025-04-13T19:09:44.969392",
     "exception": false,
     "start_time": "2025-04-13T19:09:44.962877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fac399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:09:44.984480Z",
     "iopub.status.busy": "2025-04-13T19:09:44.984109Z",
     "iopub.status.idle": "2025-04-13T19:10:20.224796Z",
     "shell.execute_reply": "2025-04-13T19:10:20.223391Z"
    },
    "papermill": {
     "duration": 35.250606,
     "end_time": "2025-04-13T19:10:20.226920",
     "exception": false,
     "start_time": "2025-04-13T19:09:44.976314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Remove conflicting packages from the Kaggle base environment.\n",
    "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
    "# Install langgraph and the packages used in this lab.\n",
    "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4ea560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:20.244262Z",
     "iopub.status.busy": "2025-04-13T19:10:20.243913Z",
     "iopub.status.idle": "2025-04-13T19:10:31.616151Z",
     "shell.execute_reply": "2025-04-13T19:10:31.614787Z"
    },
    "papermill": {
     "duration": 11.383347,
     "end_time": "2025-04-13T19:10:31.618165",
     "exception": false,
     "start_time": "2025-04-13T19:10:20.234818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6763e242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:31.635313Z",
     "iopub.status.busy": "2025-04-13T19:10:31.634955Z",
     "iopub.status.idle": "2025-04-13T19:10:36.248107Z",
     "shell.execute_reply": "2025-04-13T19:10:36.246594Z"
    },
    "papermill": {
     "duration": 4.62387,
     "end_time": "2025-04-13T19:10:36.250146",
     "exception": false,
     "start_time": "2025-04-13T19:10:31.626276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa03c7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:36.269023Z",
     "iopub.status.busy": "2025-04-13T19:10:36.268633Z",
     "iopub.status.idle": "2025-04-13T19:10:40.194308Z",
     "shell.execute_reply": "2025-04-13T19:10:40.193169Z"
    },
    "papermill": {
     "duration": 3.937343,
     "end_time": "2025-04-13T19:10:40.196307",
     "exception": false,
     "start_time": "2025-04-13T19:10:36.258964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General Python Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Kaggle Secrets\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# LangChain Utilities\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# LangChain + Gemini\n",
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    GoogleGenerativeAI,\n",
    "    GoogleGenerativeAIEmbeddings\n",
    ")\n",
    "\n",
    "# Gemini Native SDK (optional)\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73acde9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:40.216280Z",
     "iopub.status.busy": "2025-04-13T19:10:40.215645Z",
     "iopub.status.idle": "2025-04-13T19:10:40.315683Z",
     "shell.execute_reply": "2025-04-13T19:10:40.314727Z"
    },
    "papermill": {
     "duration": 0.112892,
     "end_time": "2025-04-13T19:10:40.317567",
     "exception": false,
     "start_time": "2025-04-13T19:10:40.204675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d30308",
   "metadata": {
    "papermill": {
     "duration": 0.007514,
     "end_time": "2025-04-13T19:10:40.333129",
     "exception": false,
     "start_time": "2025-04-13T19:10:40.325615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìù Document Summarizer\n",
    "\n",
    "The Document Summarizer enables students to upload learning materials (such as class notes, articles, or textbooks) and instantly receive a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260c6e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:40.350604Z",
     "iopub.status.busy": "2025-04-13T19:10:40.350241Z",
     "iopub.status.idle": "2025-04-13T19:10:41.788998Z",
     "shell.execute_reply": "2025-04-13T19:10:41.787923Z"
    },
    "papermill": {
     "duration": 1.449914,
     "end_time": "2025-04-13T19:10:41.791015",
     "exception": false,
     "start_time": "2025-04-13T19:10:40.341101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \n",
       "0           ['cs.CV', 'cs.LG']  \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2           ['cs.CV', 'cs.AI']  \n",
       "3                    ['cs.CV']  \n",
       "4           ['cs.CV', 'cs.LG']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_path = '/kaggle/input/arxiv-paper-abstracts/arxiv_data.csv'\n",
    "data2_path = '/kaggle/input/arxiv-paper-abstracts/arxiv_data_210930-054931.csv'\n",
    "\n",
    "df1 = pd.read_csv(data1_path)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d434f9db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:41.808734Z",
     "iopub.status.busy": "2025-04-13T19:10:41.808319Z",
     "iopub.status.idle": "2025-04-13T19:10:43.347521Z",
     "shell.execute_reply": "2025-04-13T19:10:43.346278Z"
    },
    "papermill": {
     "duration": 1.550226,
     "end_time": "2025-04-13T19:10:43.349553",
     "exception": false,
     "start_time": "2025-04-13T19:10:41.799327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56176</th>\n",
       "      <td>['cs.CV', 'cs.IR']</td>\n",
       "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
       "      <td>Despite the growing availability of big data i...</td>\n",
       "      <td>Despite the growing availability of big data i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56177</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']</td>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
       "      <td>This paper presents a simple end-to-end model ...</td>\n",
       "      <td>This paper presents a simple end-to-end model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56178</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56179</th>\n",
       "      <td>['stat.ML', 'cs.LG', 'math.OC']</td>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "      <td>Principal components analysis (PCA) is a well-...</td>\n",
       "      <td>Principal components analysis (PCA) is a well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56180</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'stat.ML']</td>\n",
       "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
       "      <td>SDYNA is a general framework designed to addre...</td>\n",
       "      <td>SDYNA is a general framework designed to addre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             terms  \\\n",
       "56176                           ['cs.CV', 'cs.IR']   \n",
       "56177  ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']   \n",
       "56178                                    ['cs.LG']   \n",
       "56179              ['stat.ML', 'cs.LG', 'math.OC']   \n",
       "56180                ['cs.LG', 'cs.AI', 'stat.ML']   \n",
       "\n",
       "                                                  titles  \\\n",
       "56176  Mining Spatio-temporal Data on Industrializati...   \n",
       "56177  Wav2Letter: an End-to-End ConvNet-based Speech...   \n",
       "56178  Deep Reinforcement Learning with Double Q-lear...   \n",
       "56179                        Generalized Low Rank Models   \n",
       "56180  Chi-square Tests Driven Method for Learning th...   \n",
       "\n",
       "                                               abstracts  \\\n",
       "56176  Despite the growing availability of big data i...   \n",
       "56177  This paper presents a simple end-to-end model ...   \n",
       "56178  The popular Q-learning algorithm is known to o...   \n",
       "56179  Principal components analysis (PCA) is a well-...   \n",
       "56180  SDYNA is a general framework designed to addre...   \n",
       "\n",
       "                                               summaries  \n",
       "56176  Despite the growing availability of big data i...  \n",
       "56177  This paper presents a simple end-to-end model ...  \n",
       "56178  The popular Q-learning algorithm is known to o...  \n",
       "56179  Principal components analysis (PCA) is a well-...  \n",
       "56180  SDYNA is a general framework designed to addre...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(data2_path)\n",
    "df2['summaries'] = df2['abstracts']\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf1e3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.371909Z",
     "iopub.status.busy": "2025-04-13T19:10:43.371524Z",
     "iopub.status.idle": "2025-04-13T19:10:43.388020Z",
     "shell.execute_reply": "2025-04-13T19:10:43.386949Z"
    },
    "papermill": {
     "duration": 0.027794,
     "end_time": "2025-04-13T19:10:43.389946",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.362152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"abstracts\", axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac871210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.410340Z",
     "iopub.status.busy": "2025-04-13T19:10:43.409927Z",
     "iopub.status.idle": "2025-04-13T19:10:43.419713Z",
     "shell.execute_reply": "2025-04-13T19:10:43.418579Z"
    },
    "papermill": {
     "duration": 0.021061,
     "end_time": "2025-04-13T19:10:43.421539",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.400478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56176</th>\n",
       "      <td>['cs.CV', 'cs.IR']</td>\n",
       "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
       "      <td>Despite the growing availability of big data i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56177</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']</td>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
       "      <td>This paper presents a simple end-to-end model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56178</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56179</th>\n",
       "      <td>['stat.ML', 'cs.LG', 'math.OC']</td>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "      <td>Principal components analysis (PCA) is a well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56180</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'stat.ML']</td>\n",
       "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
       "      <td>SDYNA is a general framework designed to addre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             terms  \\\n",
       "56176                           ['cs.CV', 'cs.IR']   \n",
       "56177  ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']   \n",
       "56178                                    ['cs.LG']   \n",
       "56179              ['stat.ML', 'cs.LG', 'math.OC']   \n",
       "56180                ['cs.LG', 'cs.AI', 'stat.ML']   \n",
       "\n",
       "                                                  titles  \\\n",
       "56176  Mining Spatio-temporal Data on Industrializati...   \n",
       "56177  Wav2Letter: an End-to-End ConvNet-based Speech...   \n",
       "56178  Deep Reinforcement Learning with Double Q-lear...   \n",
       "56179                        Generalized Low Rank Models   \n",
       "56180  Chi-square Tests Driven Method for Learning th...   \n",
       "\n",
       "                                               summaries  \n",
       "56176  Despite the growing availability of big data i...  \n",
       "56177  This paper presents a simple end-to-end model ...  \n",
       "56178  The popular Q-learning algorithm is known to o...  \n",
       "56179  Principal components analysis (PCA) is a well-...  \n",
       "56180  SDYNA is a general framework designed to addre...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a744d1db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.439794Z",
     "iopub.status.busy": "2025-04-13T19:10:43.439396Z",
     "iopub.status.idle": "2025-04-13T19:10:43.460399Z",
     "shell.execute_reply": "2025-04-13T19:10:43.459213Z"
    },
    "papermill": {
     "duration": 0.032035,
     "end_time": "2025-04-13T19:10:43.462107",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.430072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107950</th>\n",
       "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
       "      <td>Despite the growing availability of big data i...</td>\n",
       "      <td>['cs.CV', 'cs.IR']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107951</th>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
       "      <td>This paper presents a simple end-to-end model ...</td>\n",
       "      <td>['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107952</th>\n",
       "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "      <td>['cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107953</th>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "      <td>Principal components analysis (PCA) is a well-...</td>\n",
       "      <td>['stat.ML', 'cs.LG', 'math.OC']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107954</th>\n",
       "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
       "      <td>SDYNA is a general framework designed to addre...</td>\n",
       "      <td>['cs.LG', 'cs.AI', 'stat.ML']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107955 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   titles  \\\n",
       "0       Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1       FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2       Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3       Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4       Background-Foreground Segmentation for Interio...   \n",
       "...                                                   ...   \n",
       "107950  Mining Spatio-temporal Data on Industrializati...   \n",
       "107951  Wav2Letter: an End-to-End ConvNet-based Speech...   \n",
       "107952  Deep Reinforcement Learning with Double Q-lear...   \n",
       "107953                        Generalized Low Rank Models   \n",
       "107954  Chi-square Tests Driven Method for Learning th...   \n",
       "\n",
       "                                                summaries  \\\n",
       "0       Stereo matching is one of the widely used tech...   \n",
       "1       The recent advancements in artificial intellig...   \n",
       "2       In this paper, we proposed a novel mutual cons...   \n",
       "3       Consistency training has proven to be an advan...   \n",
       "4       To ensure safety in automated driving, the cor...   \n",
       "...                                                   ...   \n",
       "107950  Despite the growing availability of big data i...   \n",
       "107951  This paper presents a simple end-to-end model ...   \n",
       "107952  The popular Q-learning algorithm is known to o...   \n",
       "107953  Principal components analysis (PCA) is a well-...   \n",
       "107954  SDYNA is a general framework designed to addre...   \n",
       "\n",
       "                                              terms  \n",
       "0                                ['cs.CV', 'cs.LG']  \n",
       "1                       ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2                                ['cs.CV', 'cs.AI']  \n",
       "3                                         ['cs.CV']  \n",
       "4                                ['cs.CV', 'cs.LG']  \n",
       "...                                             ...  \n",
       "107950                           ['cs.CV', 'cs.IR']  \n",
       "107951  ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']  \n",
       "107952                                    ['cs.LG']  \n",
       "107953              ['stat.ML', 'cs.LG', 'math.OC']  \n",
       "107954                ['cs.LG', 'cs.AI', 'stat.ML']  \n",
       "\n",
       "[107955 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b902fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.480641Z",
     "iopub.status.busy": "2025-04-13T19:10:43.480245Z",
     "iopub.status.idle": "2025-04-13T19:10:43.495050Z",
     "shell.execute_reply": "2025-04-13T19:10:43.493919Z"
    },
    "papermill": {
     "duration": 0.026009,
     "end_time": "2025-04-13T19:10:43.496870",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.470861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=0.01, random_state=42).reset_index().drop(\"index\", axis='columns')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bd8c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.515762Z",
     "iopub.status.busy": "2025-04-13T19:10:43.515381Z",
     "iopub.status.idle": "2025-04-13T19:10:43.525393Z",
     "shell.execute_reply": "2025-04-13T19:10:43.524276Z"
    },
    "papermill": {
     "duration": 0.021293,
     "end_time": "2025-04-13T19:10:43.527117",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.505824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Multi-Object Rectified Attention Network for...</td>\n",
       "      <td>Irregular text is widely used. However, it is ...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grounding Human-to-Vehicle Advice for Self-dri...</td>\n",
       "      <td>Recent success suggests that deep neural contr...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Texture image classification based on a pseudo...</td>\n",
       "      <td>This work proposes a novel method based on a p...</td>\n",
       "      <td>['cs.CV', 'cs.NA', 'math.NA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAMAL: Context-Aware Multi-layer Attention fra...</td>\n",
       "      <td>In the last few years, Deep Convolutional Neur...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boosting Template-based SSVEP Decoding by Cros...</td>\n",
       "      <td>Objective: This study aims to establish a gene...</td>\n",
       "      <td>['cs.LG', 'eess.SP']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  A Multi-Object Rectified Attention Network for...   \n",
       "1  Grounding Human-to-Vehicle Advice for Self-dri...   \n",
       "2  Texture image classification based on a pseudo...   \n",
       "3  CAMAL: Context-Aware Multi-layer Attention fra...   \n",
       "4  Boosting Template-based SSVEP Decoding by Cros...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Irregular text is widely used. However, it is ...   \n",
       "1  Recent success suggests that deep neural contr...   \n",
       "2  This work proposes a novel method based on a p...   \n",
       "3  In the last few years, Deep Convolutional Neur...   \n",
       "4  Objective: This study aims to establish a gene...   \n",
       "\n",
       "                           terms  \n",
       "0                      ['cs.CV']  \n",
       "1                      ['cs.CV']  \n",
       "2  ['cs.CV', 'cs.NA', 'math.NA']  \n",
       "3                      ['cs.CV']  \n",
       "4           ['cs.LG', 'eess.SP']  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ccbddc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.547290Z",
     "iopub.status.busy": "2025-04-13T19:10:43.546841Z",
     "iopub.status.idle": "2025-04-13T19:10:43.552647Z",
     "shell.execute_reply": "2025-04-13T19:10:43.551507Z"
    },
    "papermill": {
     "duration": 0.01814,
     "end_time": "2025-04-13T19:10:43.554594",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.536454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text(dataframe: pd.DataFrame, max_count: int = 2) -> str:\n",
    "    entries = []\n",
    "    for i, row in dataframe[['titles', 'summaries']].dropna().head(max_count).iterrows():\n",
    "        entry = f\"Title: {row['titles']}\\nSummary: {row['summaries']}\"\n",
    "        entries.append(entry)\n",
    "    return \"\\n\\n\".join(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cebb66a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.575578Z",
     "iopub.status.busy": "2025-04-13T19:10:43.575131Z",
     "iopub.status.idle": "2025-04-13T19:10:43.581708Z",
     "shell.execute_reply": "2025-04-13T19:10:43.580245Z"
    },
    "papermill": {
     "duration": 0.019629,
     "end_time": "2025-04-13T19:10:43.583750",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.564121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_summarizer(text):\n",
    "    # Step 1: Split text into chunks\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "    )\n",
    "    docs = [Document(page_content=text)]\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Step 2: Set up Gemini via LangChain GoogleGenerativeAI\n",
    "    llm = GoogleGenerativeAI(\n",
    "        model=\"models/gemini-2.0-flash\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # Step 3: Use context as the input variable\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=(\n",
    "            \"You are an expert academic summarizer.\\n\"\n",
    "            \"Summarize the following academic research papers into concise paragraphs:\\n\\n\"\n",
    "            \"{context}\\n\\n\"\n",
    "            \"Summary:\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 4: Create the chain\n",
    "    chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # Step 5: Run the chain\n",
    "    result = chain.invoke({\"context\": split_docs})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5412f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.604103Z",
     "iopub.status.busy": "2025-04-13T19:10:43.603663Z",
     "iopub.status.idle": "2025-04-13T19:10:43.612811Z",
     "shell.execute_reply": "2025-04-13T19:10:43.611704Z"
    },
    "papermill": {
     "duration": 0.020904,
     "end_time": "2025-04-13T19:10:43.614425",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.593521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: A Multi-Object Rectified Attention Network for Scene Text Recognition\\nSummary: Irregular text is widely used. However, it is considerably difficult to\\nrecognize because of its various shapes and distorted patterns. In this paper,\\nwe thus propose a multi-object rectified attention network (MORAN) for general\\nscene text recognition. The MORAN consists of a multi-object rectification\\nnetwork and an attention-based sequence recognition network. The multi-object\\nrectification network is designed for rectifying images that contain irregular\\ntext. It decreases the difficulty of recognition and enables the\\nattention-based sequence recognition network to more easily read irregular\\ntext. It is trained in a weak supervision way, thus requiring only images and\\ncorresponding text labels. The attention-based sequence recognition network\\nfocuses on target characters and sequentially outputs the predictions.\\nMoreover, to improve the sensitivity of the attention-based sequence\\nrecognition network, a fractional pickup method is proposed for an\\nattention-based decoder in the training phase. With the rectification\\nmechanism, the MORAN can read both regular and irregular scene text. Extensive\\nexperiments on various benchmarks are conducted, which show that the MORAN\\nachieves state-of-the-art performance. The source code is available.\\n\\nTitle: Grounding Human-to-Vehicle Advice for Self-driving Vehicles\\nSummary: Recent success suggests that deep neural control networks are likely to be a\\nkey component of self-driving vehicles. These networks are trained on large\\ndatasets to imitate human actions, but they lack semantic understanding of\\nimage contents. This makes them brittle and potentially unsafe in situations\\nthat do not match training data. Here, we propose to address this issue by\\naugmenting training data with natural language advice from a human. Advice\\nincludes guidance about what to do and where to attend. We present the first\\nstep toward advice giving, where we train an end-to-end vehicle controller that\\naccepts advice. The controller adapts the way it attends to the scene (visual\\nattention) and the control (steering and speed). Attention mechanisms tie\\ncontroller behavior to salient objects in the advice. We evaluate our model on\\na novel advisable driving dataset with manually annotated human-to-vehicle\\nadvice called Honda Research Institute-Advice Dataset (HAD). We show that\\ntaking advice improves the performance of the end-to-end network, while the\\nnetwork cues on a variety of visual features that are provided by advice. The\\ndataset is available at https://usa.honda-ri.com/HAD.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = get_text(df)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a882c121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:43.634558Z",
     "iopub.status.busy": "2025-04-13T19:10:43.634173Z",
     "iopub.status.idle": "2025-04-13T19:10:47.057105Z",
     "shell.execute_reply": "2025-04-13T19:10:47.055941Z"
    },
    "papermill": {
     "duration": 3.435026,
     "end_time": "2025-04-13T19:10:47.059054",
     "exception": false,
     "start_time": "2025-04-13T19:10:43.624028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**A Multi-Object Rectified Attention Network for Scene Text Recognition:** This paper introduces a Multi-Object Rectified Attention Network (MORAN) designed to improve scene text recognition, particularly for irregular text. MORAN combines a multi-object rectification network, which corrects distorted text images to ease recognition, with an attention-based sequence recognition network that focuses on relevant characters for prediction. The rectification network is trained with weak supervision, requiring only images and text labels. A fractional pickup method is also introduced to enhance the sensitivity of the attention-based decoder during training. Experimental results demonstrate that MORAN achieves state-of-the-art performance on both regular and irregular scene text recognition benchmarks.\n",
      "\n",
      "**Grounding Human-to-Vehicle Advice for Self-driving Vehicles:** This research addresses the limitations of deep neural control networks in self-driving vehicles by incorporating natural language advice from humans. The proposed approach trains an end-to-end vehicle controller that integrates advice, adapting its visual attention and control (steering and speed) based on the guidance provided. Attention mechanisms link controller behavior to salient objects mentioned in the advice. The model is evaluated on the Honda Research Institute-Advice Dataset (HAD), a novel dataset with human-to-vehicle advice. Results show that incorporating advice improves the performance of the end-to-end network, enabling it to focus on visual features indicated by the advice.\n"
     ]
    }
   ],
   "source": [
    "summary = text_summarizer(text=text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3242a6",
   "metadata": {
    "papermill": {
     "duration": 0.008755,
     "end_time": "2025-04-13T19:10:47.077792",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.069037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîç Personalized Q&A (RAG system)\n",
    "This tool enables students to ask questions grounded in their own study materials using a Retrieval-Augmented Generation (RAG) pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aa275a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.097533Z",
     "iopub.status.busy": "2025-04-13T19:10:47.097116Z",
     "iopub.status.idle": "2025-04-13T19:10:47.103911Z",
     "shell.execute_reply": "2025-04-13T19:10:47.102645Z"
    },
    "papermill": {
     "duration": 0.018732,
     "end_time": "2025-04-13T19:10:47.105779",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.087047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 4 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "# Splitting documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "\n",
    "docs = [Document(page_content=text)]\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45500ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.126461Z",
     "iopub.status.busy": "2025-04-13T19:10:47.126019Z",
     "iopub.status.idle": "2025-04-13T19:10:47.133520Z",
     "shell.execute_reply": "2025-04-13T19:10:47.132296Z"
    },
    "papermill": {
     "duration": 0.019802,
     "end_time": "2025-04-13T19:10:47.135545",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.115743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272b108d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.156103Z",
     "iopub.status.busy": "2025-04-13T19:10:47.155673Z",
     "iopub.status.idle": "2025-04-13T19:10:47.160177Z",
     "shell.execute_reply": "2025-04-13T19:10:47.159045Z"
    },
    "papermill": {
     "duration": 0.016692,
     "end_time": "2025-04-13T19:10:47.161970",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.145278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cbf471f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.182323Z",
     "iopub.status.busy": "2025-04-13T19:10:47.181973Z",
     "iopub.status.idle": "2025-04-13T19:10:47.556192Z",
     "shell.execute_reply": "2025-04-13T19:10:47.554596Z"
    },
    "papermill": {
     "duration": 0.386644,
     "end_time": "2025-04-13T19:10:47.558135",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.171491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['846d23ba-1383-4e01-bbc4-958b37c53170', 'c171d289-aa1a-4e11-be52-d1bd3ae18bc4', 'cb1f4167-2d98-413d-ba46-04dfa092b7da']\n"
     ]
    }
   ],
   "source": [
    "# Storing Documents\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a788cc",
   "metadata": {
    "papermill": {
     "duration": 0.008934,
     "end_time": "2025-04-13T19:10:47.576530",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.567596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Simple RAG System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b700a48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.596890Z",
     "iopub.status.busy": "2025-04-13T19:10:47.596488Z",
     "iopub.status.idle": "2025-04-13T19:10:47.604782Z",
     "shell.execute_reply": "2025-04-13T19:10:47.603143Z"
    },
    "papermill": {
     "duration": 0.020625,
     "end_time": "2025-04-13T19:10:47.606846",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.586221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    temperature=0.2,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b6fea3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.627419Z",
     "iopub.status.busy": "2025-04-13T19:10:47.626987Z",
     "iopub.status.idle": "2025-04-13T19:10:47.631993Z",
     "shell.execute_reply": "2025-04-13T19:10:47.630942Z"
    },
    "papermill": {
     "duration": 0.017185,
     "end_time": "2025-04-13T19:10:47.633835",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.616650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use 4-5 sentences maximum and keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4944795a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.654226Z",
     "iopub.status.busy": "2025-04-13T19:10:47.653848Z",
     "iopub.status.idle": "2025-04-13T19:10:47.658742Z",
     "shell.execute_reply": "2025-04-13T19:10:47.657519Z"
    },
    "papermill": {
     "duration": 0.017117,
     "end_time": "2025-04-13T19:10:47.660597",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.643480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2590e480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.680659Z",
     "iopub.status.busy": "2025-04-13T19:10:47.680227Z",
     "iopub.status.idle": "2025-04-13T19:10:47.686568Z",
     "shell.execute_reply": "2025-04-13T19:10:47.685459Z"
    },
    "papermill": {
     "duration": 0.018268,
     "end_time": "2025-04-13T19:10:47.688465",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.670197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": retrieved_docs\n",
    "    }\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    formatted_prompt = prompt.format(question=state[\"question\"], context=docs_content)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8efe324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.709518Z",
     "iopub.status.busy": "2025-04-13T19:10:47.708972Z",
     "iopub.status.idle": "2025-04-13T19:10:47.714778Z",
     "shell.execute_reply": "2025-04-13T19:10:47.713282Z"
    },
    "papermill": {
     "duration": 0.018495,
     "end_time": "2025-04-13T19:10:47.716682",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.698187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap your custom functions\n",
    "retrieve_runnable = RunnableLambda(retrieve)\n",
    "generate_runnable = RunnableLambda(generate)\n",
    "\n",
    "# Chain them\n",
    "rag_chain = retrieve_runnable | generate_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a323100a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.737033Z",
     "iopub.status.busy": "2025-04-13T19:10:47.736646Z",
     "iopub.status.idle": "2025-04-13T19:10:47.741613Z",
     "shell.execute_reply": "2025-04-13T19:10:47.740351Z"
    },
    "papermill": {
     "duration": 0.017799,
     "end_time": "2025-04-13T19:10:47.743826",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.726027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_rag_question(question: str) -> str:\n",
    "    state = {\"question\": question, \"context\": [], \"answer\": \"\"}\n",
    "    return rag_chain.invoke(state)[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7f09ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T19:10:47.764611Z",
     "iopub.status.busy": "2025-04-13T19:10:47.764186Z",
     "iopub.status.idle": "2025-04-13T19:10:48.884347Z",
     "shell.execute_reply": "2025-04-13T19:10:48.883120Z"
    },
    "papermill": {
     "duration": 1.132959,
     "end_time": "2025-04-13T19:10:48.886582",
     "exception": false,
     "start_time": "2025-04-13T19:10:47.753623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of a multi-object rectified attention network (MORAN) is to recognize scene text, especially irregular text with various shapes and distortions. It uses a multi-object rectification network to correct images containing irregular text, making it easier for an attention-based sequence recognition network to read. This network then focuses on target characters and predicts them sequentially. The MORAN aims to improve the accuracy of scene text recognition for both regular and irregular text.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the purpose of a multi-object rectified attention network?\"\n",
    "answer = ask_rag_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c79157",
   "metadata": {
    "papermill": {
     "duration": 0.008928,
     "end_time": "2025-04-13T19:10:48.905533",
     "exception": false,
     "start_time": "2025-04-13T19:10:48.896605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Future Work\n",
    "To improve and expand the current system, the following future enhancements are planned:\n",
    "\n",
    "* **PDF Upload Support** ‚Äì Allow users to upload their own documents for Q&A.\n",
    "* **Persistent Vector Store** ‚Äì Replace in-memory storage with FAISS or Chroma for scalability.\n",
    "* **Better Prompts** ‚Äì Use more dynamic prompts for improved answer quality.\n",
    "* **User Feedback** ‚Äì Add ratings or comments to evaluate and refine responses.\n",
    "* **LangGraph Integration** ‚Äì Explore more advanced workflows and multi-turn reasoning.\n",
    "* **Web Interface** ‚Äì Deploy with Streamlit or Gradio for easier user interaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b9149",
   "metadata": {
    "papermill": {
     "duration": 0.010825,
     "end_time": "2025-04-13T19:10:48.925759",
     "exception": false,
     "start_time": "2025-04-13T19:10:48.914934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Thank You!\n",
    "\n",
    "This project was built as part of the GenAI Capstone.\n",
    "\n",
    "I‚Äôm proud of how far I‚Äôve come. I am excited to grow further.\n",
    "\n",
    "Thank you for reviewing ScholarAI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1680a",
   "metadata": {
    "papermill": {
     "duration": 0.010019,
     "end_time": "2025-04-13T19:10:48.945463",
     "exception": false,
     "start_time": "2025-04-13T19:10:48.935444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1611656,
     "sourceId": 2664123,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.221966,
   "end_time": "2025-04-13T19:10:52.448911",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T19:09:41.226945",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
